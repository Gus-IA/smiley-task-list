{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e94437e-1cdc-44df-b8ea-8e09b9bd47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994ebdf2-eda5-46f6-ada3-54ffa1faf3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92912bb4-3d1f-415e-9449-93523efab51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You can make funny and original jokes.\"\n",
    "user_prompt = \"Tell me a joke about Gus.\"\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca58c1b-142e-4934-862a-2debaf5daf22",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mopenai_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgpt-5-mini\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mchat_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.output_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/resources/responses/responses.py:876\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, context_management, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, prompt_cache_retention, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    838\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    839\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    874\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    875\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext_management\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_management\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1297\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1288\u001b[39m     warnings.warn(\n\u001b[32m   1289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing raw bytes as `body` is deprecated and will be removed in a future version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1290\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease pass raw bytes via the `content` parameter instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1291\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   1292\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1293\u001b[39m     )\n\u001b[32m   1294\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1295\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, content=content, files=to_httpx_files(files), **options\n\u001b[32m   1296\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1070\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1067\u001b[39m             err.response.read()\n\u001b[32m   1069\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1072\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model='gpt-5-mini',\n",
    "    input=chat_messages,\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9fd75eb-a3d3-440f-9854-4c35c821b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.tools import Tools\n",
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.llm import OpenAIClient\n",
    "from toyaikit.chat.runners import OpenAIResponsesRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a3cb3-46c9-479a-835a-e904cff212e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_agent_tools = tools.AgentTools(Path(project_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72bb43-d4f0-4fda-b651-f169789c6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_obj = Tools()\n",
    "tools_obj.add_tool(coding_agent_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b01904-84e2-442a-90f5-5674f9e35f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVELOPER_PROMPT = \"\"\"\n",
    "You are a coding agent. Your task is to modify the provided Django project template\n",
    "according to user instructions. You don't tell the user what to do; you do it yourself using the \n",
    "available tools. First, think about the sequence of steps you will do, and then \n",
    "execute the sequence.\n",
    "Always ensure changes are consistent with Django best practices and the project’s structure.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "The project is a Django 5.2.4 web application scaffolded with standard best practices. It uses:\n",
    "- Python 3.8+\n",
    "- Django 5.2.4 (as specified in pyproject.toml)\n",
    "- uv for Python environment and dependency management\n",
    "- SQLite as the default database (see settings.py)\n",
    "- Standard Django apps and a custom app called myapp\n",
    "- HTML templates for rendering views\n",
    "- TailwindCSS for styling\n",
    "\n",
    "## File Tree\n",
    "\n",
    "├── .python-version\n",
    "├── README.md\n",
    "├── manage.py\n",
    "├── pyproject.toml\n",
    "├── uv.lock\n",
    "├── myapp/\n",
    "│   ├── __init__.py\n",
    "│   ├── admin.py\n",
    "│   ├── apps.py\n",
    "│   ├── migrations/\n",
    "│   │   └── __init__.py\n",
    "│   ├── models.py\n",
    "│   ├── templates/\n",
    "│   │   └── home.html\n",
    "│   ├── tests.py\n",
    "│   └── views.py\n",
    "├── myproject/\n",
    "│   ├── __init__.py\n",
    "│   ├── asgi.py\n",
    "│   ├── settings.py\n",
    "│   ├── urls.py\n",
    "│   └── wsgi.py\n",
    "└── templates/\n",
    "    └── base.html\n",
    "\n",
    "## Content Description\n",
    "\n",
    "- manage.py: Standard Django management script for running commands.\n",
    "- README.md: Setup and run instructions, including use of uv for dependency management.\n",
    "- pyproject.toml: Project metadata and dependencies (Django 5.2.4).\n",
    "- uv.lock: Lock file for reproducible Python environments.\n",
    "- .python-version: Specifies the Python version for the project.\n",
    "- myapp/: Custom Django app with models, views, admin, tests, and a template (home.html).\n",
    "  - migrations/: Contains migration files for database schema.\n",
    "- myproject/: Django project configuration (settings, URLs, WSGI/ASGI entrypoints).\n",
    "  - settings.py: Configures installed apps, middleware, database (SQLite), templates, etc.\n",
    "- templates/: Project-level templates, including base.html.\n",
    "\n",
    "You have full access to modify, add, or remove files and code within this structure using your available tools.\n",
    "\n",
    "\n",
    "## Additional instructions\n",
    "\n",
    "- Don't execute \"runproject\", but you can execute other commands to check if the project is working.\n",
    "- Make sure you use TailwindCSS styles for making the result look beatiful\n",
    "- Keep the original URL for TailwindCSS\n",
    "- Use pictograms and emojis when possible. Font-awesome is awailable\n",
    "- Avoid putting complex logic to templates - do it on the server side when possible\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52fb62a-3cd5-4d66-a229-ebdd1662e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_interface = IPythonChatInterface()\n",
    "openai_client = OpenAIClient(client=OpenAI())\n",
    "\n",
    "runner = OpenAIResponsesRunner(\n",
    "    tools=tools_obj,\n",
    "    developer_prompt=DEVELOPER_PROMPT,\n",
    "    chat_interface=chat_interface,\n",
    "    llm_client=openai_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422f431-c957-4f78-8e04-b7498609a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a0201-fdd2-415b-88f9-a539d324d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def start():\n",
    "    project_name = input(\"Enter the new Django project name: \").strip()\n",
    "    if not project_name:\n",
    "        print(\"Project name cannot be empty.\")\n",
    "        return\n",
    "\n",
    "    if os.path.exists(project_name):\n",
    "        print(f\"Directory '{project_name}' already exists. Please choose a different name or remove the existing directory.\")\n",
    "        return\n",
    "\n",
    "    shutil.copytree('django_template', project_name)\n",
    "    print(f\"Django template copied to '{project_name}' directory.\")\n",
    "\n",
    "    return project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c396f-6001-421b-8337-99ba2cefdb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60934599-90a2-4ad0-ab07-417e8ad72c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2b28a-ea0a-48d2-aaab-1fc8b41e25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e60f02cb-22f7-47e1-8e5e-e0592568c9d1",
   "metadata": {},
   "source": [
    "coding_agent_tools = tools.AgentTools(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c805819-2716-48cd-aea4-e65d73498dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb770b-5fab-4078-8f86-0cd0113a30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, function_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeed4c0-d87d-4cb2-943c-16d8d0d29ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "@function_tool\n",
    "def make_joke(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a personalized joke using the provided name.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): The name to insert into the joke.\n",
    "\n",
    "    Returns:\n",
    "        str: A joke with the name included.\n",
    "    \"\"\"\n",
    "    jokes = [\n",
    "        f\"Why did {name} bring a pencil to the party? Because he wanted to draw some attention!\",\n",
    "        f\"Did you hear about {name}'s bakery? Business is on a roll!\",\n",
    "        f\"{name} walked into a library and asked for a burger. The librarian said, 'This is a library.' So {name} whispered, 'Can I get a burger?'\",\n",
    "        f\"When {name} does push-ups, the Earth moves down.\",\n",
    "        f\"{name} told a chemistry joke... but there was no reaction.\",\n",
    "    ]\n",
    "    return random.choice(jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cdbba-bb5c-4019-a6a7-124118664b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_joke_tool = function_tool(make_joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed21a8c-c373-442d-8585-7a7493165394",
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_system_prompt = \"\"\"\n",
    "You can make funny and original jokes.\n",
    "Find out the user's name to make the joke personalized.\n",
    "\"\"\"\n",
    "\n",
    "joke_agent = Agent(\n",
    "    name=\"JokeAgent\",\n",
    "    instructions=joke_system_prompt,\n",
    "    tools=[make_joke_tool],\n",
    "    model='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a013a5-6217-4b72-9e1e-6cfbd935197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.chat.runners import OpenAIAgentsSDKRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2df89-f4e3-418e-bbc4-b792d5b882c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = IPythonChatInterface()\n",
    "runner = OpenAIAgentsSDKRunner(\n",
    "    chat_interface=interface,\n",
    "    agent=coding_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5794c74-3988-4680-9109-56183945d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Agents SDK is async, so we need to use await here\n",
    "await runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca4e35-c579-4b76-8749-2588bd07e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_tools = tools.AgentTools(Path(todo-agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f7865-282c-4dda-8c96-8fae59181453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.tools import wrap_instance_methods\n",
    "\n",
    "coding_agent_tools_list = wrap_instance_methods(function_tool, agent_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d19160-6859-4381-9f39-6d4fc9f18b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_agent = Agent(\n",
    "    name=\"CodingAgent\",\n",
    "    instructions=DEVELOPER_PROMPT,\n",
    "    tools=coding_agent_tools_list,\n",
    "    model='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480326f-66ba-4277-9d1b-13b1fe4c773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = OpenAIAgentsSDKRunner(\n",
    "    chat_interface=interface,\n",
    "    agent=coding_agent\n",
    ")\n",
    "await runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f265d92-516e-4a81-b234-36087f1e3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PydaticAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d19ec5-0653-482e-b64d-eb0290315671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8adf81c-07c8-4223-a12d-fd78cfc265af",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'todo-pydantic'\n",
    "agent_tools = tools.AgentTools(Path(project_name))\n",
    "\n",
    "coding_agent_tools_list = [\n",
    "    agent_tools.execute_bash_command,\n",
    "    agent_tools.read_file,\n",
    "    agent_tools.search_in_files,\n",
    "    agent_tools.see_file_tree,\n",
    "    agent_tools.write_file\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4942b-1d1e-4cef-9644-3f0fbfba627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.tools import get_instance_methods\n",
    "\n",
    "coding_agent_tools_list = get_instance_methods(agent_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8190ad7-08b2-46e7-9c19-4bb7937e8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_agent = Agent(\n",
    "    'openai:gpt-4o-mini',\n",
    "    #'anthropic:claude-3-5-sonnet-latest',\n",
    "    instructions=DEVELOPER_PROMPT,\n",
    "    tools=coding_agent_tools_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bec53e-9ed6-4909-a620-a8e6aebf3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.chat.runners import PydanticAIRunner\n",
    "\n",
    "chat_interface = IPythonChatInterface()\n",
    "\n",
    "runner = PydanticAIRunner(\n",
    "    chat_interface=chat_interface,\n",
    "    agent=coding_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd043e-5c0d-40b6-ae49-ed637acbec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "await runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e957b101-f691-4386-9595-86b52a634222",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Z.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e1d92-adbe-428c-a15f-77f23fd0af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "zai_client = OpenAI(\n",
    "    api_key=os.getenv('ZAI_API_KEY'),\n",
    "    base_url='https://api.z.ai/api/paas/v4/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82364ad9-143c-47fc-9b00-3fb6fc9fbe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_tools = tools.AgentTools(Path(z.ai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a0cdb-8ec5-4b65-a4da-41f83d33fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.chat.runners import OpenAIChatCompletionsRunner\n",
    "from toyaikit.llm import OpenAIChatCompletionsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9632e-a685-4e9e-a464-4d5b5710b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_obj = Tools()\n",
    "tools_obj.add_tools(agent_tools)\n",
    "\n",
    "llm_client = OpenAIChatCompletionsClient(model='glm-4.5', client=zai_client)\n",
    "chat_interface = IPythonChatInterface()\n",
    "\n",
    "runner = OpenAIChatCompletionsRunner(\n",
    "    tools=tools_obj,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    llm_client=llm_client\n",
    ")\n",
    "runner.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
